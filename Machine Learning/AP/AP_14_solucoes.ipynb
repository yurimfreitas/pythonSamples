{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vamos aplicar o que aprendemos sobre pipelines\n",
        "*   Complete com o código em falta\n",
        "*   Sempre que necessário, **substitua** ___\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "[documentação](https://scikit-learn.org/stable/index.html) <br>\n",
        "dataset: [fonte](https://www.kaggle.com/datasets/mirichoi0218/insurance)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7UqvAzOuK_SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Vamos aplicar o que aprendemos sobre pipelines](#scrollTo=7UqvAzOuK_SN)\n",
        "\n",
        ">[1. Corra a primeira célula de código para obter o dataframe com que vamos trabalhar](#scrollTo=25DtwghMIQqJ)\n",
        "\n",
        ">[2. Trate os dados em falta](#scrollTo=glt7JqnNdHxk)\n",
        "\n",
        ">[3. Faça train_test_split](#scrollTo=Rq7QOxUC9Y4u)\n",
        "\n",
        ">[4. Aplique o pipeline](#scrollTo=wM4XJr63vizy)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "7UIUmwrhK7QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.&nbsp;Corra a primeira célula de código para obter o dataframe com que vamos trabalhar"
      ],
      "metadata": {
        "id": "25DtwghMIQqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# faça o upload do ficheiro csv associado à atividade\n",
        "\n",
        "# vamos importar a biblioteca\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# vamos importar o dataframe do ficheiro .csv\n",
        "df = pd.read_csv(\"insurance.csv\")"
      ],
      "metadata": {
        "id": "OkUD9YVbIMEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veja as 5 primeiras linhas do dataframe\n",
        "df.head()\n",
        "# veja a forma do dataframe: quantas linhas, quantas colunas?\n",
        "df.shape\n",
        "# veja a informação sobre o dataframe\n",
        "df.info()\n",
        "# veja a descrição das variáveis numéricas\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "Chlqc16uIpbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.&nbsp;Trate os dados em falta"
      ],
      "metadata": {
        "id": "glt7JqnNdHxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remova a coluna quase sem informação\n",
        "df.drop(columns='region', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "wwDNLaj7-0TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remova os dois casos simples\n",
        "df.dropna(subset=['sex'], inplace=True)"
      ],
      "metadata": {
        "id": "MamCEuDMupzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.&nbsp;Faça train_test_split"
      ],
      "metadata": {
        "id": "Rq7QOxUC9Y4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defina a variável alvo\n",
        "target_variable = \"charges\"\n",
        "\n",
        "# train_test split usando a função train_test_split\n",
        "X = df.drop(target_variable, axis = 1)\n",
        "y = df[target_variable]\n",
        "y.sum()/len(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 12)\n"
      ],
      "metadata": {
        "id": "aWoz4UHRu0--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.&nbsp;Aplique o pipeline"
      ],
      "metadata": {
        "id": "wM4XJr63vizy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importe os transformers\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# defina o processamento das variáveis numéricas\n",
        "numeric_features = [\"age\", \"bmi\"]\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# defina o processamento das variáveis categóricas\n",
        "categorical_features = [\"children\", \"sex\"]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# combine os processos\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', num_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# crie o pipeline com processamento e modelação\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor())\n",
        "])\n",
        "\n",
        "\n",
        "# importe a grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# defina os dados para a grid\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [25, 50, 100, 200],\n",
        "    'regressor__max_depth': [2, 5, 10, 20]\n",
        "}\n",
        "\n",
        "# defina as métricas de scoring\n",
        "scoring = {\n",
        "    'mse': 'neg_mean_squared_error',\n",
        "    'r2': 'r2'\n",
        "}\n",
        "\n",
        "# construa a grid search\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scoring, refit='r2')\n",
        "\n",
        "# faça o fit da grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# veja os melhores parameters\n",
        "print(\"Best parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# obtenha o melhor modelo\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# faça predict usando o melhor modelo\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# visualize os resíduos\n",
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "\n",
        "display = PredictionErrorDisplay(y_true = y_test, y_pred = y_pred)\n",
        "display.plot()\n",
        "\n",
        "# importe a lista de métricas\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_percentage_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "# MAE\n",
        "mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# MSE\n",
        "mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# RMSE\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# MAPE\n",
        "mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "# R2\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "T07Wn5C4vhy_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}